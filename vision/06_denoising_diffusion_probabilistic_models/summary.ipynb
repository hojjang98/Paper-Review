{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed815592",
   "metadata": {},
   "source": [
    "# ðŸ“„ Paper Summary: Denoising Diffusion Probabilistic Models (DDPM)\n",
    "\n",
    "**Title**: Denoising Diffusion Probabilistic Models  \n",
    "**Authors**: Jonathan Ho, Ajay Jain, Pieter Abbeel  \n",
    "**Published in**: NeurIPS 2020  \n",
    "**Link**: [https://arxiv.org/abs/2006.11239](https://arxiv.org/abs/2006.11239)  \n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Day 1 â€“ Abstract & Introduction  \n",
    "\n",
    "### ðŸ“Œ Background & Motivation  \n",
    "Deep generative models such as GANs, VAEs, autoregressive models, and flow-based models have produced high-quality results across multiple modalities.  \n",
    "However, each has critical limitations:  \n",
    "- **VAE**: often generates blurry outputs due to variational approximations  \n",
    "- **GAN**: unstable training, prone to mode collapse  \n",
    "- **Flow-based models**: strong inductive biases, complex architectures  \n",
    "\n",
    "These issues motivate the exploration of new approaches for stable and high-quality image generation.  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Core Idea  \n",
    "- A **diffusion model** reframes image generation as a **denoising problem**.  \n",
    "- **Forward process**: gradually corrupt data by adding small amounts of Gaussian noise until all signal is destroyed.  \n",
    "- **Reverse process**: train a parameterized Markov chain to progressively remove noise, reconstructing data from random noise.  \n",
    "- Gaussian noise assumption makes training simple and tractable.  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Main Contributions  \n",
    "1. **High-quality synthesis**: Comparable or superior to GANs.  \n",
    "2. **Stable training**: Avoids adversarial instabilities.  \n",
    "3. **Simple objective**: Reduces to predicting noise with MSE.  \n",
    "4. **Theory**: Connects diffusion models to score matching and Langevin dynamics.  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Early Results  \n",
    "- **CIFAR-10**: IS = 9.46, FID = 3.17 (SOTA at the time).  \n",
    "- **LSUN 256Ã—256**: On par with ProgressiveGAN.  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ TL;DR  \n",
    "Diffusion models = add Gaussian noise step by step â†’ train to reverse the corruption.  \n",
    "Stable, simple, and capable of SOTA results.  \n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Day 2 â€“ Forward Process (Noising)  \n",
    "\n",
    "### ðŸ“Œ Step 1: Markov Chain Definition  \n",
    "The forward diffusion process gradually corrupts data through a Markov chain:  \n",
    "\\[\n",
    "q(x_{1:T}|x_0) = \\prod_{t=1}^T q(x_t|x_{t-1})\n",
    "\\]  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Step 2: One-Step Transition  \n",
    "Each step adds Gaussian noise with variance schedule $\\beta_t$:  \n",
    "\\[\n",
    "q(x_t | x_{t-1}) = \\mathcal{N}(x_t;\\sqrt{1-\\beta_t}\\,x_{t-1}, \\beta_t I)\n",
    "\\]  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Step 3: Direct Sampling from $x_0$  \n",
    "\\[\n",
    "q(x_t|x_0) = \\mathcal{N}\\big(x_t;\\sqrt{\\bar{\\alpha}_t}x_0,(1-\\bar{\\alpha}_t)I\\big)\n",
    "\\]  \n",
    "\\[\n",
    "x_t = \\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\,\\epsilon\n",
    "\\]  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Notes  \n",
    "- Forward process is **parameter-free**.  \n",
    "- At $t=T$, $x_T \\sim \\mathcal{N}(0,I)$ â†’ pure noise.  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ TL;DR  \n",
    "Forward = gradually **destroy** data into Gaussian noise, fully tractable.  \n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Day 3 â€“ Reverse Process (Denoising)  \n",
    "\n",
    "### ðŸ“Œ Step 1: Goal  \n",
    "Model  \n",
    "\\[\n",
    "q(x_{t-1}|x_t)\n",
    "\\]  \n",
    "to reconstruct data. This is intractable â†’ approximate.  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Step 2: Gaussian Approximation  \n",
    "Assume reverse step is Gaussian:  \n",
    "\\[\n",
    "p_\\theta(x_{t-1}|x_t) = \\mathcal{N}(x_{t-1}; \\mu_\\theta(x_t,t), \\Sigma_\\theta(x_t,t))\n",
    "\\]  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Step 3: Noise Prediction  \n",
    "From forward equation:  \n",
    "\\[\n",
    "x_t = \\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\epsilon\n",
    "\\]  \n",
    "Train a network $\\epsilon_\\theta(x_t,t)$ to predict $\\epsilon$.  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Step 4: Training Objective  \n",
    "\\[\n",
    "L_{\\text{simple}} = \\mathbb{E}_{t,x_0,\\epsilon}[\\|\\epsilon - \\epsilon_\\theta(x_t,t)\\|^2]\n",
    "\\]  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Notes  \n",
    "- Reverse process is the **learned part**.  \n",
    "- Training = stable MSE objective.  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ TL;DR  \n",
    "Reverse = **denoising**. Train NN to predict noise, minimize MSE.  \n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Day 4 â€“ Experiments & Results  \n",
    "\n",
    "### ðŸ“Œ Setup  \n",
    "- **Datasets**: CIFAR-10, LSUN, CelebA HQ  \n",
    "- **Metrics**: FID, IS  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Results  \n",
    "- **CIFAR-10**: IS = 9.46, FID = 3.17 â†’ SOTA.  \n",
    "- **LSUN**: Comparable to ProgressiveGAN.  \n",
    "- **CelebA HQ**: High-quality high-res samples.  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Observations  \n",
    "- Samples = sharp & diverse, no mode collapse.  \n",
    "- Training = stable.  \n",
    "- Diffusion matches/exceeds GANs.  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ TL;DR  \n",
    "DDPM = GAN-quality results without adversarial headaches.  \n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Day 5 â€“ Discussion & Conclusion  \n",
    "\n",
    "### ðŸ“Œ Key Insights  \n",
    "- Diffusion = strong alternative to GAN/VAEs.  \n",
    "- Stable training with simple loss.  \n",
    "- Theoretical bridge to score matching & Langevin dynamics.  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Limitations  \n",
    "- **Slow sampling** (hundredsâ€“thousands of steps).  \n",
    "- **High compute cost**.  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Future Directions  \n",
    "1. Faster samplers (â†’ DDIM, latent diffusion).  \n",
    "2. Broader domains: audio, video, text, multimodal.  \n",
    "3. Hybrid models combining paradigms.  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Final Takeaway  \n",
    "Diffusion models = **add noise â†’ learn to remove it**.  \n",
    "Simple yet powerful, they laid the foundation for modern generative AI (e.g., Stable Diffusion, Imagen, DALLÂ·E 2).  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
