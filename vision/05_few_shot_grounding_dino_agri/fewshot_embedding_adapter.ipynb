{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47f9a92a",
   "metadata": {},
   "source": [
    "# Few-shot Embedding Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b43c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from typing import Optional, Literal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9021ccdf",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdbe3a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def few_shot_indices(ds, k: int = 4, seed: int = 42):\n",
    "    rng = random.Random(seed)\n",
    "    by_class = {}\n",
    "    for idx, (_, c) in enumerate(ds):\n",
    "        by_class.setdefault(c, []).append(idx)\n",
    "    chosen = []\n",
    "    for c, idxs in by_class.items():\n",
    "        rng.shuffle(idxs)\n",
    "        chosen.extend(idxs[:k])\n",
    "    return chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9271036a",
   "metadata": {},
   "source": [
    "# Encoder helpers (frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19cbbe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_encoder(model: nn.Module):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_images(encoder: nn.Module, x: torch.Tensor) -> torch.Tensor:\n",
    "    feats = encoder.encode_image(x) if hasattr(encoder, \"encode_image\") else encoder(x)\n",
    "    feats = F.normalize(feats, dim=-1)\n",
    "    return feats  # [B, D]\n",
    "\n",
    "def feature_dim(encoder: nn.Module, sample: torch.Tensor) -> int:\n",
    "    with torch.no_grad():\n",
    "        f = encoder.encode_image(sample) if hasattr(encoder, \"encode_image\") else encoder(sample)\n",
    "    return f.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bda42a",
   "metadata": {},
   "source": [
    "# Learnable class embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "319a05eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_class_embeddings(\n",
    "    num_classes: int,\n",
    "    dim: int,\n",
    "    tokens_per_class: int = 4,\n",
    "    device: Optional[str] = None,\n",
    "    init_scale: float = 0.02,\n",
    ") -> nn.Parameter:\n",
    "    emb = nn.Parameter(torch.randn(num_classes, tokens_per_class, dim, device=device) * init_scale)\n",
    "    emb.requires_grad_(True)\n",
    "    return emb  # shape: [C, T, D]\n",
    "\n",
    "# optional tiny attention head for token pooling\n",
    "def create_token_attn(dim: int, device: Optional[str] = None) -> nn.Linear:\n",
    "    attn = nn.Linear(dim, 1, bias=False).to(device)\n",
    "    return attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afea75af",
   "metadata": {},
   "source": [
    "# Logits from features + embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42adcebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def normalize_embeddings(emb: torch.Tensor) -> torch.Tensor:\n",
    "    return F.normalize(emb, dim=-1)\n",
    "\n",
    "def logits_from(\n",
    "    feats: torch.Tensor,          # [B, D]\n",
    "    emb: torch.Tensor,            # [C, T, D] (learnable)\n",
    "    mode: Literal[\"max\", \"mean\", \"attn\"] = \"max\",\n",
    "    temperature: Optional[nn.Parameter] = None,  # e.g., nn.Parameter(torch.tensor(10.0, device=device))\n",
    "    token_attn: Optional[nn.Module] = None,      # nn.Linear(D,1)\n",
    ") -> torch.Tensor:\n",
    "    E = normalize_embeddings(emb)                 # [C, T, D]\n",
    "    Fz = F.normalize(feats, dim=-1)               # [B, D]\n",
    "    sim = torch.einsum(\"bd,ctd->bct\", Fz, E)      # [B, C, T]\n",
    "\n",
    "    if mode == \"max\":\n",
    "        logit = sim.amax(dim=-1)                  # [B, C]\n",
    "    elif mode == \"mean\":\n",
    "        logit = sim.mean(dim=-1)\n",
    "    elif mode == \"attn\":\n",
    "        assert token_attn is not None, \"token_attn required for mode='attn'\"\n",
    "        w = torch.softmax(token_attn(E).squeeze(-1), dim=-1)  # [C, T]\n",
    "        logit = (sim * w.unsqueeze(0)).sum(dim=-1)\n",
    "    else:\n",
    "        raise ValueError(\"mode must be one of {'max','mean','attn'}\")\n",
    "\n",
    "    if temperature is not None:\n",
    "        logit = temperature * logit\n",
    "    return logit  # [B, C]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc91d9d",
   "metadata": {},
   "source": [
    "# Optimizer factory (emb + optional temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bc3a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(emb: nn.Parameter, lr: float = 5e-3, weight_decay: float = 1e-4, temperature: nn.Parameter = None):\n",
    "    params = [emb]\n",
    "    if temperature is not None:\n",
    "        params.append(temperature)\n",
    "    return torch.optim.AdamW(params, lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3585922c",
   "metadata": {},
   "source": [
    "# Train / Eval loops (emb-only training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "942f0acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    encoder: nn.Module,\n",
    "    emb: nn.Parameter,\n",
    "    loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: str,\n",
    "    mode: Literal[\"max\",\"mean\",\"attn\"] = \"max\",\n",
    "    temperature: nn.Parameter = None,\n",
    "    token_attn: nn.Module = None,\n",
    ") -> tuple[float, float]:\n",
    "    encoder.eval()  # frozen\n",
    "    tot = cor = n = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            feats = encode_images(encoder, x)     # [B, D]\n",
    "        logit = logits_from(feats, emb, mode=mode, temperature=temperature, token_attn=token_attn)\n",
    "        loss = F.cross_entropy(logit, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tot += loss.item() * x.size(0)\n",
    "        cor += (logit.argmax(1) == y).sum().item()\n",
    "        n += x.size(0)\n",
    "    return tot / max(n,1), cor / max(n,1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(\n",
    "    encoder: nn.Module,\n",
    "    emb: nn.Parameter,\n",
    "    loader: DataLoader,\n",
    "    device: str,\n",
    "    mode: Literal[\"max\",\"mean\",\"attn\"] = \"max\",\n",
    "    temperature: nn.Parameter = None,\n",
    "    token_attn: nn.Module = None,\n",
    "    topk: int = 5,\n",
    ") -> dict:\n",
    "    encoder.eval()\n",
    "    tot = cor1 = cork = n = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        feats = encode_images(encoder, x)\n",
    "        logit = logits_from(feats, emb, mode=mode, temperature=temperature, token_attn=token_attn)\n",
    "        loss = F.cross_entropy(logit, y)\n",
    "        tot += loss.item() * x.size(0)\n",
    "        pred1 = logit.argmax(1)\n",
    "        cor1 += (pred1 == y).sum().item()\n",
    "        topk_idx = logit.topk(min(topk, logit.size(1)), dim=1).indices\n",
    "        cork += (topk_idx == y.unsqueeze(1)).any(dim=1).sum().item()\n",
    "        n += x.size(0)\n",
    "    return {\n",
    "        \"loss\": tot / max(n,1),\n",
    "        \"top1\": cor1 / max(n,1),\n",
    "        \"topk\": cork / max(n,1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943a0baf",
   "metadata": {},
   "source": [
    "# Save / Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39aa3dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(emb: nn.Parameter, path: str = \"fewshot_emb.pt\"):\n",
    "    torch.save(emb.detach().cpu(), path)\n",
    "\n",
    "def load_embeddings(path: str, device: Optional[str] = None) -> nn.Parameter:\n",
    "    tensor = torch.load(path, map_location=device if device else \"cpu\")\n",
    "    param = nn.Parameter(tensor.to(device) if device else tensor)\n",
    "    param.requires_grad_(True)\n",
    "    return param"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
